# ğŸ§  PrÃ¡ctica ROS 2: OdometrÃ­a Visual con Optical Flow

## ğŸ¯ Objetivo

Desarrollar un sistema de odometrÃ­a visual bÃ¡sico utilizando flujo Ã³ptico en ROS 2. El sistema debe estimar la posiciÃ³n y orientaciÃ³n del robot en el plano (2D) a partir del anÃ¡lisis del movimiento aparente en una secuencia de imÃ¡genes capturadas por una cÃ¡mara.

---

## ğŸ“š MotivaciÃ³n

En escenarios donde no se dispone de sensores de posicionamiento precisos (como GPS, IMU o encoders), la visiÃ³n por computador ofrece una alternativa de bajo costo para estimar el movimiento de un robot.

El Optical Flow permite detectar y cuantificar el desplazamiento aparente de pÃ­xeles entre imÃ¡genes sucesivas. Aunque no proporciona una escala mÃ©trica por sÃ­ mismo, puede utilizarse como base para una estimaciÃ³n incremental de la trayectoria del robot.

Esta prÃ¡ctica tiene como objetivo:
- Comprender los principios bÃ¡sicos del flujo Ã³ptico.
- Aplicar tÃ©cnicas de seguimiento de puntos (Lucas-Kanade).
- Estimar una transformaciÃ³n afÃ­n entre frames para calcular traslaciÃ³n y rotaciÃ³n.
- Publicar esta informaciÃ³n como odometrÃ­a en ROS 2.
- Visualizar resultados en RViz y herramientas de ROS.

---

## ğŸ”§ Pasos de desarrollo

### 1. Crear el paquete ROS 2
Se genera un paquete Python con `ros2 pkg create`, siguiendo el estilo estÃ¡ndar de ROS 2. Se aÃ±aden los archivos necesarios: nodo principal, launch files y configuraciÃ³n.

### 2. Implementar el flujo Ã³ptico
Se utiliza OpenCV para:
- Detectar caracterÃ­sticas (puntos de interÃ©s).
- Hacer seguimiento de esos puntos entre imÃ¡genes sucesivas con Lucas-Kanade.
- Calcular la transformaciÃ³n afÃ­n entre los conjuntos de puntos.

### 3. Estimar odometrÃ­a
La transformaciÃ³n afÃ­n (traslaciÃ³n + rotaciÃ³n) permite estimar la posiciÃ³n y orientaciÃ³n relativa del robot en el plano 2D. Esta informaciÃ³n se acumula y se publica como un mensaje `nav_msgs/Odometry`.

### 4. Publicar transformaciones TF
Se utiliza `tf2_ros` para emitir un `TransformStamped` que relaciona el marco `odom` con el marco `base_link`. Esto permite a RViz representar la trayectoria del robot correctamente en el espacio.

### 5. Publicar la imagen visual
La imagen con vectores de flujo se convierte en un `sensor_msgs/Image` y se publica en un tÃ³pico para poder visualizarla con `rqt_image_view` o `image_view`.

### 6. Filtrar el ruido de flujo Ã³ptico
Para evitar que pequeÃ±os cambios visuales se interpreten como desplazamientos reales, se descartan los vectores de flujo cuya magnitud es inferior a un umbral configurable.

### 7. Visualizar en RViz
Se crea un launch file que lanza tanto el nodo como RViz, configurado con vistas para:
- La imagen del flujo Ã³ptico.
- El frame `base_link`.
- La trayectoria sobre `/odom`.

---

## ğŸ“ˆ Limitaciones conocidas

- No se corrige la **deriva acumulativa**.
- El sistema no tiene informaciÃ³n de escala real.
- Cambios de iluminaciÃ³n o textura afectan el flujo.
- No se estima profundidad ni se maneja el movimiento fuera del plano.

---

## ğŸ§© Extensiones posibles

- FusiÃ³n con IMU mediante `robot_localization`.
- EstimaciÃ³n de la escala usando una cÃ¡mara estÃ©reo o referencias visuales.
- Uso de algoritmos SLAM como `ORB-SLAM2` o `RTAB-Map`.
- Mejora de la robustez con detectores como ORB o SIFT.
- AplicaciÃ³n en drones o robots mÃ³viles reales.

---

# ğŸ”— Del Flujo Ã“ptico a la OdometrÃ­a Visual y SLAM

## 1ï¸âƒ£ Flujo Ã“ptico: el punto de partida

El **flujo Ã³ptico** estima cÃ³mo se mueven los pÃ­xeles entre dos imÃ¡genes consecutivas.  
Es Ãºtil para:

- DetecciÃ³n de movimiento
- Seguimiento de puntos
- EstimaciÃ³n de velocidad aparente

Sin embargo:

- Solo proporciona **movimiento relativo local**
- No conoce la **geometrÃ­a 3D** ni la posiciÃ³n absoluta
- No mantiene una **trayectoria acumulativa estable**

---

## 2ï¸âƒ£ OdometrÃ­a Visual: estimar el movimiento de la cÃ¡mara

La **odometrÃ­a visual (Visual Odometry, VO)** es un paso mÃ¡s allÃ¡ del flujo Ã³ptico.

Su objetivo es:

> Estimar la **pose (posiciÃ³n y orientaciÃ³n)** de la cÃ¡mara a lo largo del tiempo, **integrando informaciÃ³n visual entre mÃºltiples fotogramas**.

### ğŸ“· Â¿CÃ³mo lo hace?

- Detecta puntos clave (features) en imÃ¡genes sucesivas
- Establece correspondencias (matches) entre esos puntos
- Usa triangulaciÃ³n o PnP para estimar el movimiento entre imÃ¡genes
- Integra estos desplazamientos en una trayectoria de la cÃ¡mara

ğŸ“Œ Algunos mÃ©todos de VO usan directamente **optical flow** (por ejemplo, KLT tracker) para seguir puntos clave entre fotogramas.

---

### ğŸ” RelaciÃ³n entre Optical Flow y Visual Odometry

| Concepto         | Optical Flow                      | Visual Odometry                       |
|------------------|-----------------------------------|----------------------------------------|
| Entrada          | Dos imÃ¡genes consecutivas         | Secuencia de imÃ¡genes                 |
| Resultado        | Movimiento de pÃ­xeles             | Pose de la cÃ¡mara                     |
| Tipo de salida   | Campo de vectores 2D              | TransformaciÃ³n 3D (R, t)              |
| Dependencias     | Gradientes locales                | GeometrÃ­a de la cÃ¡mara                |
| Uso de features  | Opcional (denso o escaso)         | Generalmente usa puntos clave         |
| PrecisiÃ³n        | Local                             | Global (a corto plazo)                |

---

## 3ï¸âƒ£ Â¿DÃ³nde entra SLAM? (ORB-SLAM, RTAB-Map)

El problema de la odometrÃ­a visual es que **acumula error** con el tiempo (deriva).  
AhÃ­ es donde entra **SLAM (Simultaneous Localization and Mapping)**:

> SLAM no solo estima la trayectoria de la cÃ¡mara (como VO), sino que tambiÃ©n **construye un mapa** del entorno y corrige errores mediante **cerrado de bucles** y **relocalizaciÃ³n**.

### ğŸ§± Â¿QuÃ© aÃ±ade SLAM sobre VO?

- ğŸ—ºï¸ **Mapa del entorno**
- ğŸ” **Cierre de bucles** para reducir error acumulado
- ğŸ“ **Re-localizaciÃ³n** en zonas ya visitadas
- ğŸ”§ **OptimizaciÃ³n global** de la trayectoria

---

## ğŸ§  De flujo Ã³ptico a mapeo robusto: la progresiÃ³n lÃ³gica

```text
Flujo Ã“ptico
   â†“
OdometrÃ­a Visual
   â†“
SLAM (ej. ORB-SLAM, RTAB-Map)
